{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# Breast cancer detector with tumor type\n",
    "\n",
    "We will use Logical regression model. 2 is mean that the tumor is benign, 4 is malignant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWd1UlMnhT2s"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1VMqkGvhc3-"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n",
    "x = dataset.iloc[:, 1:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 '?' '?' ... 3 1 1]\n",
      " [5 '4' '4' ... 3 2 1]\n",
      " [3 '1' '1' ... 3 1 1]\n",
      " ...\n",
      " [5 '10' '10' ... 8 10 2]\n",
      " [4 '8' '6' ... 10 6 1]\n",
      " [4 '8' '8' ... 10 4 1]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have string values, that should be numeric. This values are string because of the '?' character.** To deal with this we will turn all the \"?\" characters into NaN with to_numeric(). We use for loop because to_numeric function takes an 1D array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x[1])):\n",
    "    x[:, i] = pd.to_numeric(x[:,i], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking care of missing data\n",
    "\n",
    "We have missing data, which represented by \"?\". We have to replace them with meaningful data to process. To do this we will use most_frequent strategy of the SimpleImputer class.\n",
    "\n",
    "**Note: Another approach is we would use the strategy most_frequent instead of average and with that we wouldn't have to convert the whole set to integer so we wouldn't use the last for loop. It doesn't change the accuracy of the model with this set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "imputer.fit(x[:,:])\n",
    "x[:,:] = imputer.transform(x[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.0 3.1375358166189113 3.2106017191977076 ... 3.0 1.0 1.0]\n",
      " [5.0 4.0 4.0 ... 3.0 2.0 1.0]\n",
      " [3.0 1.0 1.0 ... 3.0 1.0 1.0]\n",
      " ...\n",
      " [5.0 10.0 10.0 ... 8.0 10.0 2.0]\n",
      " [4.0 8.0 6.0 ... 10.0 6.0 1.0]\n",
      " [4.0 8.0 8.0 ... 10.0 4.0 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvxIPVyMhmKp"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb6jCOCQiAmP"
   },
   "source": [
    "## Training the Logical Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKYVQH-l5NpE"
   },
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 4]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "print(np.concatenate((y_pred.reshape(-1, 1), y_test.reshape(-1, 1)), axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4Hwj34ziWQW"
   },
   "source": [
    "## Making the Confusion Matrix and Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82  3]\n",
      " [ 1 54]]\n",
      "0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "print(cm)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZ-j28aPihZx"
   },
   "source": [
    "## Computing the accuracy with k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.60 %\n",
      "Standard Deviation: 2.58 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMgnogy4MthjceNfhB196rJ",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
